Description:
# A simple version of the ID3 decision tree algorithm.  
</br>This is the basic algorithm discussed in your book and the slides, using information gain as the splitting criteria, but with the extension to handle multiple classes (rather than just positive and negative examples). You may write this program in the language of your choice (out of the usual suspects).  I recommend using the same language as you used for program 2, since some aspects of the task are the same.  Always look for opportunities to reuse code when permissible and possible.  Your code will need to allow the user to do several things:
1)	Produce a decision tree from a list of examples
2)	Given a decision tree and a file of instances, produce a file of labeled examples.
3)	Print out a decision tree
4)	Read a file of test examples and report the accuracy of the tree on those examples
5)	Quit the program
## To Compile
in Anaconda install
- python-graphviz
- pydot
